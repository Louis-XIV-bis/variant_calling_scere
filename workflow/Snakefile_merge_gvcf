# Author: Louis OLLIVIER (louis.xiv.bis@gmail.com)
# Date : February 2025

import re 
configfile: "config/config.yaml"

# Load the predefined resource requirments ("config/resources.yaml")
import yaml, json, numpy as np, pandas as pd
with open("config/resources.yaml", "r") as f:
    resources = yaml.safe_load(f)

conda: "workflow/envs/environment.yaml"

############# Downloading, merging and filtering the information files #############
# Download all the tsv files from the ENA IDs. They contain all the information
# requiered for the rest of the pipeline (sample ID, ftp link to dl fastq, etc).
# After that, it's merged into one unique file and filtered / processed (e.g. keep
# only S.cere sequences). Then, a csv table is created for each ENA_strain ID from the table.

# Done by the Python script ran before this pipeline, we just read the list of IDs
try:   
    with open('results/tables_merge_gvcf/ENA_strain_list.json', 'r') as file:
        ENA_strain_list = np.array(json.load(file))
except FileNotFoundError:
    raise FileNotFoundError("Please, make sure you ran the 'generate_table.py' script before that pipeline (python generate_tables.py merge_gvcf). If you did, the output file was not correctly created.")

# Chromosome ID defined in the script (specie specific, check NCBI or one gvcf)
CHROMOSOMES = config['chromosomes']

# Generate all the possible combinations of contigs and strains for the output
output_merge_chrom_vcf = [f"results/vcf/unfiltered_merged_strains_{chrom}.vcf.gz" for chrom in CHROMOSOMES]

localrules:
    all,

rule all:
    input:
        expand("results/gvcf/{ENA_strain}.g.vcf.gz", ENA_strain=ENA_strain_list),
        "results/samples.map", 
        output_merge_chrom_vcf,
        "results/vcf/unfiltered_yeast_strains.vcf.gz",
        "results/vcf/filtered_yeast_strains.vcf.gz",
        "results/vcf/filtered_repremoved_yeast_strains.vcf.gz",

# Create a "sample map" that is a tsv file of the sample name and the associated gvcf file path.
rule generate_sample_map:
    input:
        expand("results/gvcf/{ENA_strain}.g.vcf.gz", ENA_strain=ENA_strain_list), 
    output:
        "results/samples.map", 
    resources:
        slurm_partition=resources["generate_sample_map"]["partition"],
        mem_mb=resources["generate_sample_map"]["memory"],
        tasks=resources["generate_sample_map"]["tasks"],
        cpus_per_task=resources["generate_sample_map"]["cpu_tasks"],
        jobname=resources["generate_sample_map"]["jobname"],
    log:
        stdout="logs/generate_sample_map.stdout",
        stderr="logs/generate_sample_map.stderr",
    run:
        with open(output[0], "w") as f:
            for input_file in input:
                # Extract the sample name using regex
                match = re.search(r"PRJ[\w]+_(\S+?)(?=\.g\.vcf\.gz)", input_file)
                if match:
                    sample_name = match.group(1)  # The captured sample name
                    f.write(f"{sample_name}\t{input_file}\n")
                else:
                    raise ValueError(f"Sample name not found in file: {input_file}")


# Create a genomic DB for each chromosome of all samples then use it 
# to get the raw VCF per chromosome (for all samples)
rule merge_gvcfs:
    input:
        "results/samples.map"
    output:
        "results/vcf/unfiltered_merged_strains_{chrom}.vcf.gz",
    params:
        ref_genome=config["ref_genome"],
        threads=resources["merge_gvcfs"]["cpu_tasks"],
    threads: resources["merge_gvcfs"]["cpu_tasks"],
    resources:
        slurm_partition=resources["merge_gvcfs"]["partition"],
        mem_mb=resources["merge_gvcfs"]["memory"],
        tasks=resources["merge_gvcfs"]["tasks"],
        cpus_per_task=resources["merge_gvcfs"]["cpu_tasks"],
        jobname=resources["merge_gvcfs"]["jobname"],
    log:
        genomicsdb="logs/genomicsdb_{chrom}.log", 
        genotypegvcfs="logs/genotypegvcfs_{chrom}.log",
    shell:
        '''
        # Create the GenomicDBImport command for this chromosome
        gatk --java-options "-Xmx230g -Xms230g" GenomicsDBImport \
        --genomicsdb-workspace-path "results/chrom_DB_{wildcards.chrom}" \
        --sample-name-map {input} \
        --verbosity DEBUG \
        --batch-size 100 \
        --intervals "{wildcards.chrom}" \
        --reference {params.ref_genome} \
        --reader-threads {params.threads} \
        --overwrite-existing-genomicsdb-workspace true \
        > "{log.genomicsdb}" 2>&1 

        # Use the GenomicDB to generate the final VCF (if needed)
        gatk --java-options "-Xmx230g -Xms230g" GenotypeGVCFs \
            -R {params.ref_genome} \
            -V "gendb://results/chrom_DB_{wildcards.chrom}" \
            -O "{output}" \
            > "{log.genotypegvcfs}" 2>&1
        '''

# Merge all the per chromosome VCF into one unique VCF file 
rule merge_vcfs:
    input:
        expand("results/vcf/unfiltered_merged_strains_{chrom}.vcf.gz", chrom=CHROMOSOMES)
    output:
        "results/vcf/unfiltered_yeast_strains.vcf.gz"
    params:
        ref_genome=config["ref_genome"]
    threads: resources["merge_vcfs"]["cpu_tasks"]
    resources:
        slurm_partition=resources["merge_vcfs"]["partition"],
        mem_mb=resources["merge_vcfs"]["memory"],
        tasks=resources["merge_vcfs"]["tasks"],
        cpus_per_task=resources["merge_vcfs"]["cpu_tasks"],
        jobname=resources["merge_vcfs"]["jobname"],
    log:
        stdout="logs/merge_vcfs.stdout",
        stderr="logs/merge_vcfs.stderr"
    shell:
        '''
        echo "{input}" | tr ' ' '\n' > tomerge.list ; \
        gatk --java-options "-Xmx450g -Xms450g" MergeVcfs \
        -O "{output}" \
        -I tomerge.list \
        > "{log.stdout}" 2> "{log.stderr}"; \
        rm tomerge.list
        '''
        

# Fill the filter column in the VCF: hard filtering based on previous tests (remove if TRUE)
# Do not flag as pass if missing value except for the RankSum scores because they requiere 
# heterozygous sites (if it's homozygous, can't compute these score but sites are still valid!)
rule add_filter_vcf:
    input:
        "results/vcf/unfiltered_yeast_strains.vcf.gz",
    output:
        temp("results/vcf/addfilter_yeast_strains.vcf.gz"),
    params:
        ref_genome=config["ref_genome"],
    threads: resources["add_filter_vcf"]["cpu_tasks"]
    resources:
        slurm_partition=resources["add_filter_vcf"]["partition"],
        mem_mb=resources["add_filter_vcf"]["memory"],
        tasks=resources["add_filter_vcf"]["tasks"],
        cpus_per_task=resources["add_filter_vcf"]["cpu_tasks"],
        jobname=resources["add_filter_vcf"]["jobname"],
    log:
        stdout="logs/add_filter_vcf.stdout", stderr="logs/add_filter_vcf.stderr"
    shell:
        '''
        gatk --java-options "-Xmx450g -Xms450g" VariantFiltration -R {params.ref_genome} \
        -V {input} \
        --filter-expression "QD < 2.0 || QD == '.'" --filter-name "QD2_missing" \
        --filter-expression "SOR > 2.0 || SOR == '.'" --filter-name "SOR2_missing" \
        --filter-expression "FS > 60.0 || FS == '.'" --filter-name "FS60_missing" \
        --filter-expression "MQ < 50.0 || MQ == '.'" --filter-name "MQ50_missing" \
        --filter-expression "MQRankSum < -10.0" --filter-name "MQRankSum-10" \
        --filter-expression "ReadPosRankSum < -5.0" --filter-name "ReadPosRankSum-5" \
        --filter-expression "ReadPosRankSum > 5.0" --filter-name "ReadPosRankSum5" \
        --filter-expression "BaseQRankSum < -2.0" --filter-name "BaseQRankSum-2" \
        -O {output} > {log.stdout} 2> {log.stderr}
        '''

# Remove the SNP that didn't pass the filter (based on the FILTER column)
rule filter_vcf:
    input:
        "results/vcf/addfilter_yeast_strains.vcf.gz",
    output:
        "results/vcf/filtered_yeast_strains.vcf.gz",
    threads: resources["filter_vcf"]["cpu_tasks"]
    resources:
        slurm_partition=resources["filter_vcf"]["partition"],
        mem_mb=resources["filter_vcf"]["memory"],
        tasks=resources["filter_vcf"]["tasks"],
        cpus_per_task=resources["filter_vcf"]["cpu_tasks"],
        jobname=resources["filter_vcf"]["jobname"],
    log:
        stderr="logs/filter_vcf.stderr"
    shell:
        '''
        bcftools view -f PASS -o {output} -Oz {input} 2> {log.stderr}; \
        tabix -p vcf {output}
        '''

# Remove repeted regions from the genome (see resources/README.md) 
# for more info about the input file
rule remove_rep_regions:
    input:
        "results/vcf/filtered_yeast_strains.vcf.gz",
    output:
        "results/vcf/filtered_repremoved_yeast_strains.vcf.gz",
    params:
        rep_regions=config["rep_regions"]
    threads: resources["remove_rep_regions"]["cpu_tasks"]
    resources:
        slurm_partition=resources["remove_rep_regions"]["partition"],
        mem_mb=resources["remove_rep_regions"]["memory"],
        tasks=resources["remove_rep_regions"]["tasks"],
        cpus_per_task=resources["remove_rep_regions"]["cpu_tasks"],
        jobname=resources["remove_rep_regions"]["jobname"],
    log:
        stderr="logs/remove_rep_regions.stderr"
    shell:
        '''   
        (bcftools view -h {input}; \
        bedtools subtract -a {input} -b {params.rep_regions}) | bgzip -c > {output} 2> {log.stderr}; \
        tabix -p vcf {output}
        '''        