# Author: Louis OLLIVIER (louis.xiv.bis@gmail.com)
# Date : February 2023 

configfile: "config/config.yaml"

# Load the predefined resource requirments ("config/resources.yaml")
import yaml, json, numpy as np, pandas as pd
with open("config/resources.yaml", "r") as f:
    resources = yaml.safe_load(f)

conda: "workflow/envs/environment.yaml"

############# Downloading, merging and filtering the information files #############
# Download all the tsv files from the ENA IDs. They contain all the information
# requiered for the rest of the pipeline (sample ID, ftp link to dl fastq, etc).
# After that, it's merged into one unique file and filtered / processed (e.g. keep
# only S.cere sequences). Then, a csv table is created for each ENA_strain ID from the table.

# Done by the Python script ran before this pipeline, we just read the list of IDs
try:   
    with open('results/tables_merge_gvcf/ENA_strain_list.json', 'r') as file:
        ENA_strain_list = np.array(json.load(file))
except FileNotFoundError:
    raise FileNotFoundError("Please, make sure you ran the 'generate_table.py' script before that pipeline (python generate_tables.py merge_gvcf). If you did, the output file was not correctly created.")

localrules:
    all,

rule all: 
    input:
        "results/vcf/unfiltered_yeast_strains.vcf.gz",
        "results/vcf/filtered_yeast_strains.vcf.gz",
        "results/vcf/filtered_repremoved_yeast_strains.vcf",


# Combine per sample gVCF into multi-sample gVCF using CombineGVCFs
# (since we only produce gVCF w/ HaplotypeCaller it's OK tu use this tool).


rule merge_gvcfs:
    input:
        expand("results/gvcf/{ENA_strain}.g.vcf.gz", ENA_strain=ENA_strain_list),
    output:
        temp("results/vcf/merged_strains.g.vcf.gz"),
    params:
        ref_genome=config["ref_genome"],
        file_name="list_gvcf.list",
    threads: resources["merge_gvcfs"]["cpu_tasks"]
    resources:
        slurm_partition=resources["merge_gvcfs"]["partition"],
        mem_mb=resources["merge_gvcfs"]["memory"],
        tasks=resources["merge_gvcfs"]["tasks"],
        cpus_per_task=resources["merge_gvcfs"]["cpu_tasks"],
        jobname=resources["merge_gvcfs"]["jobname"],
    log:
        stdout="logs/merge_gvcfs.stdout", stderr="logs/merge_gvcfs.stderr"
    run:
        with open(params.file_name, "w") as file:
            for element in input:
                file.write(str(element) + "\n")

        shell(
            "gatk CombineGVCFs -R {params.ref_genome} -O {output} -V {params.file_name} > {log.stdout} 2> {log.stderr}"
        )
        os.remove(params.file_name)


# Convert the multi-sample gVCF to the multi-sample VCF file
# using GenotypeGVCFs.


rule gvcf_to_vcf:
    input:
        "results/vcf/merged_strains.g.vcf.gz",
    output:
        "results/vcf/unfiltered_yeast_strains.vcf.gz",
    params:
        ref_genome=config["ref_genome"],
    threads: resources["gvcf_to_vcf"]["cpu_tasks"]
    resources:
        slurm_partition=resources["gvcf_to_vcf"]["partition"],
        mem_mb=resources["gvcf_to_vcf"]["memory"],
        tasks=resources["gvcf_to_vcf"]["tasks"],
        cpus_per_task=resources["gvcf_to_vcf"]["cpu_tasks"],
        jobname=resources["gvcf_to_vcf"]["jobname"],
    log:
        stdout="logs/gvcf_to_vcf.stdout", stderr="logs/gvcf_to_vcf.stderr"
    shell:
        "gatk GenotypeGVCFs -R {params.ref_genome} -V {input} -O {output} > {log.stdout} 2> {log.stderr}"


# Fill the filter column in the VCF: hard filtering based on previous tests (remove if TRUE)


rule add_filter_vcf:
    input:
        "results/vcf/unfiltered_yeast_strains.vcf.gz",
    output:
        temp("results/vcf/addfilter_yeast_strains.vcf.gz"),
    params:
        ref_genome=config["ref_genome"],
    threads: resources["add_filter_vcf"]["cpu_tasks"]
    resources:
        slurm_partition=resources["add_filter_vcf"]["partition"],
        mem_mb=resources["add_filter_vcf"]["memory"],
        tasks=resources["add_filter_vcf"]["tasks"],
        cpus_per_task=resources["add_filter_vcf"]["cpu_tasks"],
        jobname=resources["add_filter_vcf"]["jobname"],
    log:
        stdout="logs/add_filter_vcf.stdout", stderr="logs/add_filter_vcf.stderr"
    shell:
        """
        gatk VariantFiltration -R {params.ref_genome} \
        -V {input} \
        -filter "QD < 10.0" --filter-name "QD10" \
        -filter "SOR > 3.0" --filter-name "SOR3" \
        -filter "FS > 60.0" --filter-name "FS60" \
        -filter "MQ < 50.0" --filter-name "MQ50" \
        -O {output} > {log.stdout} 2> {log.stderr}
        """


# #    "-filter 'MQRankSum < (-12.5)' --filter-name 'MQRankSum-12.5' "
# #    "-filter 'ReadPosRankSum < (-8)' --filter-name ReadPosRankSum-8' "

# Remove the SNP that didn't pass the filter (based on the FILTER column)


rule filter_vcf:
    input:
        "results/vcf/addfilter_yeast_strains.vcf.gz",
    output:
        "results/vcf/filtered_yeast_strains.vcf.gz",
    threads: resources["filter_vcf"]["cpu_tasks"]
    resources:
        slurm_partition=resources["filter_vcf"]["partition"],
        mem_mb=resources["filter_vcf"]["memory"],
        tasks=resources["filter_vcf"]["tasks"],
        cpus_per_task=resources["filter_vcf"]["cpu_tasks"],
        jobname=resources["filter_vcf"]["jobname"],
    log:
        stderr="logs/filter_vcf.stderr"
    shell:
        "vcftools --gzvcf {input} --remove-filtered-all --recode --stdout | gzip -c > {output} 2> {log.stderr}"

############# Remove repeted regions #############
# Remove repeted regions from the genome (see resources/README.md) 
# for more info about the input file

rule remove_rep_regions:
    priority: 12
    input:
        "results/vcf/filtered_yeast_strains.vcf.gz",
    output:
        "results/vcf/filtered_repremoved_yeast_strains.vcf.gz",
    params:
        rep_regions=config["rep_regions"],
        tmp_vcf="temp_filtered_repremoved_yeast_strains.vcf."
    threads: resources["remove_rep_regions"]["cpu_tasks"]
    resources:
        slurm_partition=resources["remove_rep_regions"]["partition"],
        mem_mb=resources["remove_rep_regions"]["memory"],
        tasks=resources["remove_rep_regions"]["tasks"],
        cpus_per_task=resources["remove_rep_regions"]["cpu_tasks"],
        jobname=resources["remove_rep_regions"]["jobname"],
    log:
        stderr="logs/remove_rep_regions.stderr"
    shell:
        """   
        bcftools view -h {input} > {params.temp_vcf} 2> {log.stderr}; \ 
        bedtools subtract -a {input} -b {params.rep_regions} >> {params.temp_vcf} 2>> {log.stderr}; \
        tabix -p vcf {params.temp_vcf}; \ 
        bgzip -c {params.temp_vcf} > {output}; \ 
        rm temp_{wildcards.contig}.vcf
        """